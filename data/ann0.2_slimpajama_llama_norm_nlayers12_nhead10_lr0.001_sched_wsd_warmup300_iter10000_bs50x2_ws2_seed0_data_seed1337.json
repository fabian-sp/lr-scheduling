{
    "summary": {
        "iter": 10000,
        "_wandb": {
            "runtime": 1141
        },
        "val/loss": 3.184088706970215,
        "_timestamp": 1715382529.9666042,
        "optimized_parameters": 93159040,
        "val/perplexity": 24.145223242292435,
        "train/perplexity": 30.613786883750223,
        "final-val/perplexity": 24.882914590370728,
        "lr": 0,
        "_step": 51,
        "iter_dt": 0.436096778,
        "val/acc": 0.42984986305236816,
        "final-val/acc": 0.4252538979053498,
        "final-val/loss": 3.214183568954468,
        "_runtime": 1140.5809082984924,
        "parameters": 93159040,
        "train/loss": 3.421452760696411
    },
    "config": {
        "lr": 0.001,
        "moe": false,
        "opt": "adamw",
        "bias": false,
        "seed": 0,
        "beta1": 0.9,
        "beta2": 0.95,
        "dtype": "bfloat16",
        "model": "llama_norm",
        "wandb": true,
        "device": "cuda:0",
        "n_embd": 640,
        "n_head": 10,
        "compile": true,
        "dataset": "slimpajama",
        "dropout": 0,
        "n_layer": 12,
        "init_std": 0.02,
        "wa_dtype": "float32",
        "acc_steps": 2,
        "data_seed": 1337,
        "ema_decay": 0.95,
        "grad_clip": 1,
        "scale_emb": 10,
        "scheduler": "wsd",
        "tokenizer": "gpt2",
        "batch_size": 50,
        "from_dense": false,
        "iterations": 10000,
        "vocab_size": 50304,
        "wa_horizon": 500,
        "world_size": 2,
        "auto_resume": true,
        "data_in_ram": false,
        "moe_routing": "standard_gating",
        "multiple_of": 256,
        "resume_from": "/mloscratch/homes/haegele/improvegpt/exps/sl93_slimpajama_llama_norm_nlayers12_nhead10_lr0.001_sched_wsd_warmup300_iter25000_bs50x2_ws2_seed0_data_seed1337/ckpts/8000",
        "rmsnorm_eps": 1e-05,
        "scale_depth": 1.4,
        "wa_interval": 5,
        "datasets_dir": "./datasets/",
        "ema_interval": 10,
        "eval_batches": 32,
        "full_eval_at": [
            10000,
            17500,
            25000
        ],
        "log_dynamics": false,
        "log_interval": 50,
        "warmup_steps": 300,
        "weight_decay": 0.1,
        "config_format": "base",
        "eval_interval": 200,
        "wandb_project": "scaling-laws-slimpajama",
        "parallel_block": false,
        "use_pretrained": "none",
        "weight_average": false,
        "capacity_factor": 2,
        "eval_seq_prefix": "none",
        "experiment_name": null,
        "moe_num_experts": 8,
        "moe_router_loss": "load_balancing_z_loss",
        "sequence_length": 512,
        "wa_use_temp_dir": false,
        "wsd_fract_decay": 0.2,
        "ema_after_warmup": false,
        "scale_base_model": 256,
        "wa_sweep_horizon": false,
        "wandb_run_prefix": "ann0.2",
        "max_num_wa_sweeps": 5,
        "moe_softmax_order": "topk_softmax",
        "moe_z_loss_factor": 0.01,
        "mlp_dim_exp_factor": 1,
        "plot_router_logits": false,
        "wsd_final_lr_scale": 0,
        "distributed_backend": "nccl",
        "dynamics_logger_cfg": "./src/logger/rotational_logger.yaml",
        "moe_aux_loss_factor": 0.1,
        "results_base_folder": "./exps",
        "latest_ckpt_interval": 1000,
        "wsd_exponential_decay": false,
        "moe_num_shared_experts": 0,
        "moe_entropy_loss_factor": 0.01,
        "moe_num_experts_per_tok": 2,
        "permanent_ckpt_interval": 0,
        "exponential_moving_average": false
    },
    "name": "ann0.2_slimpajama_llama_norm_nlayers12_nhead10_lr0.001_sched_wsd_warmup300_iter10000_bs50x2_ws2_seed0_data_seed1337",
    "history": {
        "final-val": {
            "iter": [
                10000
            ],
            "final_val_best_perplexity_wa": [],
            "final_val_best_loss_wa": [],
            "final_val_loss": [
                3.2141835689544678
            ],
            "final_val_perplexity": [
                24.882914590370728
            ]
        },
        "val": {
            "iter": [
                8000,
                8200,
                8400,
                8600,
                8800,
                9000,
                9200,
                9400,
                9600,
                9800
            ],
            "val_perplexity": [
                28.26019184006995,
                27.713432036447507,
                27.27763539768476,
                26.735616048918267,
                26.258752398437625,
                25.797546384551723,
                25.31649733667973,
                24.876561645649513,
                24.486776196229478,
                24.145223242292435
            ],
            "val_loss": [
                3.341456413269043,
                3.3219194412231445,
                3.3060693740844727,
                3.285998821258545,
                3.2680015563964844,
                3.250281572341919,
                3.2314584255218506,
                3.21392822265625,
                3.1981353759765625,
                3.184088706970215
            ],
            "val_acc": [
                0.4113708436489105,
                0.41386717557907104,
                0.41579222679138184,
                0.41780638694763184,
                0.42002806067466736,
                0.4218420386314392,
                0.423980712890625,
                0.42638546228408813,
                0.42824095487594604,
                0.42984986305236816
            ]
        },
        "train": {
            "iter": [
                8050,
                8100,
                8150,
                8200,
                8250,
                8300,
                8350,
                8400,
                8450,
                8500,
                8550,
                8600,
                8650,
                8700,
                8750,
                8800,
                8850,
                8900,
                8950,
                9000,
                9050,
                9100,
                9150,
                9200,
                9250,
                9300,
                9350,
                9400,
                9450,
                9500,
                9550,
                9600,
                9650,
                9700,
                9750,
                9800,
                9850,
                9900,
                9950,
                10000
            ],
            "train_perplexity": [
                34.496949758453894,
                32.424523031760074,
                31.82101541282491,
                33.39617037624035,
                34.46147017543195,
                29.763945365549347,
                34.34416968404334,
                26.214683701730088,
                27.346561783488717,
                30.80986916479542,
                25.747172926863563,
                23.8139070768375,
                32.19291042552093,
                22.743487211839092,
                32.98177126735613,
                35.26429457510379,
                30.501990037363015,
                30.057895778667753,
                28.708407372740144,
                30.861081410496713,
                28.18938608208605,
                31.380318171638663,
                34.95789635119455,
                25.546886152677423,
                27.889002452807397,
                30.584291686683905,
                31.117302069587037,
                27.51965709183692,
                32.43903662180304,
                34.46477326590943,
                25.796832923632632,
                25.881645146385722,
                30.999756423601596,
                28.20129125406478,
                28.82940747342869,
                25.454545638186268,
                28.854169437269878,
                27.14990118662719,
                28.938088787073855,
                30.613786883750223
            ],
            "train_lr": [
                0.000975,
                0.00095,
                0.000925,
                0.0009000000000000001,
                0.000875,
                0.00085,
                0.000825,
                0.0008,
                0.0007750000000000001,
                0.00075,
                0.000725,
                0.0007,
                0.000675,
                0.0006500000000000001,
                0.000625,
                0.0006,
                0.000575,
                0.00055,
                0.0005250000000000001,
                0.0005,
                0.000475,
                0.00045,
                0.00042500000000000003,
                0.0004,
                0.000375,
                0.00035,
                0.000325,
                0.00030000000000000003,
                0.000275,
                0.00025,
                0.000225,
                0.00019999999999999996,
                0.00017500000000000005,
                0.00015000000000000001,
                0.000125,
                9.999999999999998e-05,
                7.499999999999995e-05,
                5.000000000000004e-05,
                2.500000000000002e-05,
                0
            ],
            "train_loss": [
                3.5408732891082764,
                3.478917360305786,
                3.4601292610168457,
                3.508443593978882,
                3.539844274520874,
                3.3933000564575195,
                3.5364346504211426,
                3.266321897506714,
                3.3085930347442627,
                3.427837371826172,
                3.2483270168304443,
                3.170271873474121,
                3.4717485904693604,
                3.1242809295654297,
                3.495957374572754,
                3.562873363494873,
                3.4177942276000977,
                3.403127670288086,
                3.357192277908325,
                3.4294981956481934,
                3.3389477729797363,
                3.446183204650879,
                3.5541467666625977,
                3.2405176162719727,
                3.3282346725463867,
                3.4204888343811035,
                3.4377663135528564,
                3.3149027824401855,
                3.4793648719787598,
                3.539940118789673,
                3.250253915786743,
                3.2535362243652344,
                3.4339816570281982,
                3.339370012283325,
                3.361398220062256,
                3.236896514892578,
                3.3622567653656006,
                3.3013756275177,
                3.3651609420776367,
                3.421452760696411
            ]
        },
        "wa": {
            "iter": [],
            "val_perplexity_wa": [],
            "val_loss_wa": [],
            "val_acc_wa": [],
            "val_best_perplexity_wa": []
        },
        "ema": {
            "iter": [],
            "val_perplexity_ema": [],
            "val_acc_ema": [],
            "val_loss_ema": []
        }
    }
}