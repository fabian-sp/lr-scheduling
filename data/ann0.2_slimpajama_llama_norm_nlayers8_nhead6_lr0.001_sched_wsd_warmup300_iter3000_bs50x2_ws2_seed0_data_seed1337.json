{
    "summary": {
        "_step": 26,
        "iter_dt": 0.142830289,
        "_timestamp": 1715257270.3406014,
        "train/perplexity": 39.644086778460505,
        "val/loss": 3.664539337158203,
        "train/loss": 3.679944276809693,
        "final-val/perplexity": 39.11941848865162,
        "lr": 0,
        "val/acc": 0.3816455006599426,
        "final-val/acc": 0.3800400495529175,
        "optimized_parameters": 33479040,
        "iter": 3000,
        "_wandb": {
            "runtime": 235
        },
        "_runtime": 235.34970545768735,
        "parameters": 33479040,
        "final-val/loss": 3.666621446609497,
        "val/perplexity": 39.03805236839715
    },
    "config": {
        "lr": 0.001,
        "moe": false,
        "opt": "adamw",
        "bias": false,
        "seed": 0,
        "beta1": 0.9,
        "beta2": 0.95,
        "dtype": "bfloat16",
        "model": "llama_norm",
        "wandb": true,
        "device": "cuda:0",
        "n_embd": 384,
        "n_head": 6,
        "compile": true,
        "dataset": "slimpajama",
        "dropout": 0,
        "n_layer": 8,
        "init_std": 0.02,
        "wa_dtype": "float32",
        "acc_steps": 2,
        "data_seed": 1337,
        "ema_decay": 0.95,
        "grad_clip": 1,
        "scale_emb": 10,
        "scheduler": "wsd",
        "tokenizer": "gpt2",
        "batch_size": 50,
        "from_dense": false,
        "iterations": 3000,
        "vocab_size": 50304,
        "wa_horizon": 500,
        "world_size": 2,
        "auto_resume": true,
        "data_in_ram": false,
        "moe_routing": "standard_gating",
        "multiple_of": 256,
        "resume_from": "/mloscratch/homes/haegele/improvegpt/exps/sl_slimpajama_llama_norm_nlayers8_nhead6_lr0.001_sched_wsd_warmup300_iter10000_bs50x2_ws2_seed0_data_seed1337/ckpts/2000",
        "rmsnorm_eps": 1e-05,
        "scale_depth": 1.4,
        "wa_interval": 5,
        "datasets_dir": "./datasets/",
        "ema_interval": 10,
        "eval_batches": 32,
        "full_eval_at": [
            3000,
            7000,
            10000
        ],
        "log_dynamics": false,
        "log_interval": 50,
        "warmup_steps": 300,
        "weight_decay": 0.1,
        "config_format": "base",
        "eval_interval": 200,
        "wandb_project": "slimpajama",
        "parallel_block": false,
        "use_pretrained": "none",
        "weight_average": false,
        "capacity_factor": 2,
        "eval_seq_prefix": "none",
        "experiment_name": null,
        "moe_num_experts": 8,
        "moe_router_loss": "load_balancing_z_loss",
        "sequence_length": 512,
        "wa_use_temp_dir": false,
        "wsd_fract_decay": 0.2,
        "ema_after_warmup": false,
        "scale_base_model": 256,
        "wa_sweep_horizon": false,
        "wandb_run_prefix": "ann0.2",
        "max_num_wa_sweeps": 5,
        "moe_softmax_order": "topk_softmax",
        "moe_z_loss_factor": 0.01,
        "mlp_dim_exp_factor": 1,
        "plot_router_logits": false,
        "wsd_final_lr_scale": 0,
        "distributed_backend": "nccl",
        "dynamics_logger_cfg": "./src/logger/rotational_logger.yaml",
        "moe_aux_loss_factor": 0.1,
        "results_base_folder": "./exps",
        "latest_ckpt_interval": 1000,
        "wsd_exponential_decay": false,
        "moe_num_shared_experts": 0,
        "moe_entropy_loss_factor": 0.01,
        "moe_num_experts_per_tok": 2,
        "permanent_ckpt_interval": 0,
        "exponential_moving_average": false
    },
    "name": "ann0.2_slimpajama_llama_norm_nlayers8_nhead6_lr0.001_sched_wsd_warmup300_iter3000_bs50x2_ws2_seed0_data_seed1337",
    "history": {
        "final-val": {
            "iter": [
                3000
            ],
            "final_val_best_perplexity_wa": [],
            "final_val_best_loss_wa": [],
            "final_val_loss": [
                3.666621446609497
            ],
            "final_val_perplexity": [
                39.11941848865162
            ]
        },
        "val": {
            "iter": [
                2000,
                2200,
                2400,
                2600,
                2800
            ],
            "val_perplexity": [
                46.18569037279303,
                44.9588367944177,
                43.852266699560005,
                41.35101794481993,
                39.03805236839715
            ],
            "val_loss": [
                3.832672595977783,
                3.8057498931884766,
                3.7808289527893066,
                3.722099542617798,
                3.664539337158203
            ],
            "val_acc": [
                0.3651135265827179,
                0.36757326126098633,
                0.3695470988750458,
                0.3752478063106537,
                0.3816455006599426
            ]
        },
        "train": {
            "iter": [
                2050,
                2100,
                2150,
                2200,
                2250,
                2300,
                2350,
                2400,
                2450,
                2500,
                2550,
                2600,
                2650,
                2700,
                2750,
                2800,
                2850,
                2900,
                2950,
                3000
            ],
            "train_perplexity": [
                59.52800501532375,
                60.335569565728285,
                47.774934289095114,
                54.11200915216875,
                47.91738987380481,
                37.41626661955099,
                51.84328743277482,
                51.82531853374246,
                60.174039985748166,
                47.49519892311011,
                50.755164602120985,
                43.3324248746458,
                48.23169578269629,
                41.13712347939135,
                58.240142196669005,
                39.37196960559767,
                46.1898969647094,
                40.624548910726766,
                43.261342265290274,
                39.644086778460505
            ],
            "train_lr": [
                0.001,
                0.001,
                0.001,
                0.001,
                0.001,
                0.001,
                0.001,
                0.001,
                0.0009166666666666666,
                0.0008333333333333334,
                0.00075,
                0.0006666666666666668,
                0.0005833333333333333,
                0.0005,
                0.00041666666666666664,
                0.0003333333333333334,
                0.00025,
                0.00016666666666666663,
                8.333333333333337e-05,
                0
            ],
            "train_loss": [
                4.08644962310791,
                4.099924564361572,
                3.8665037155151367,
                3.991058826446533,
                3.869481086730957,
                3.622107982635498,
                3.948228120803833,
                3.9478814601898193,
                4.097243785858154,
                3.860631227493286,
                3.927016019821167,
                3.7689037322998047,
                3.87601900100708,
                3.7169134616851807,
                4.064577579498291,
                3.6730566024780273,
                3.832763671875,
                3.7043750286102295,
                3.7672619819641113,
                3.6799442768096924
            ]
        },
        "wa": {
            "iter": [],
            "val_perplexity_wa": [],
            "val_loss_wa": [],
            "val_acc_wa": [],
            "val_best_perplexity_wa": []
        },
        "ema": {
            "iter": [],
            "val_perplexity_ema": [],
            "val_acc_ema": [],
            "val_loss_ema": []
        }
    }
}